version: '3.8'
services:
# IA Local: Ollama
  ollama:
    image: ollama/ollama
    container_name: ollama_service
    entrypoint: ["/bin/sh", "-c"]
    command: ["/bin/ollama serve & sleep 10 && ollama pull phi3 && wait"]
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    restart: unless-stopped

 #Agente Gerador: FastAPI/Python
  agente-gerador:
    build:
      context: ./agente-gerador
    container_name: agente_gerador_service
    depends_on:
      - ollama
    environment:
      - OLLAMA_HOST=http://ollama:11434
    ports:
      - "8001:8001"
    restart: always

  #Agente Revisor: Node.js
  agente-revisor:
    build:
      context: ./agente-revisor
    container_name: agente_revisor_service
    env_file:
      - ./.env
    ports:
      - "8002:8002" 
    restart: always

 #API Gateway: Node.js
  api-gateway:
    build:
      context: .
      dockerfile: ./api-gateway/Dockerfile
    container_name: api_gateway_service
    depends_on:
      - agente-gerador
      - agente-revisor
    environment:
      - AGENTE_GERADOR_URL=http://agente-gerador:8001
      - AGENTE_REVISOR_URL=http://agente-revisor:8002
    ports:
      - "3000:3000"
    restart: always

volumes:
  ollama_data: